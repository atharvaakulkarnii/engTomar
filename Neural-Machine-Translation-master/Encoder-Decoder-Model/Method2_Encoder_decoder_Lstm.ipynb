{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Method2-Encoder-decoder-Lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iTkGlxwgmYL"
      },
      "source": [
        "# Training Encoder decoder lstm with Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0b45f7c-c38d-466f-a5f4-375f09af651d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8c5a33e-fc53-4cca-aeef-0028b69d2ad2"
      },
      "source": [
        "# get data\n",
        "df= pd.read_csv(\"/content/drive/MyDrive/ML/rnn/Machine_Translation/Data/cleaned.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40397cd7-d8ec-41f1-837f-a3bdeeae704a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0a3d9bb9-e71e-4d25-eddf-86d3662e54bc"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41023</th>\n",
              "      <td>just saying you do not like fish because of th...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41024</th>\n",
              "      <td>the japanese parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41025</th>\n",
              "      <td>tom tried to sell his old vcr instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्हीसीआर फेकून टाकण्याऐवजी व...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41026</th>\n",
              "      <td>you cannot view flash content on an ipad howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही पण तुम्ही त्या...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41027</th>\n",
              "      <td>in  roger miller recorded a song called you do...</td>\n",
              "      <td>मध्ये रॉजर मिलरने यू डोन्ट वॉन्ट माय लव्ह नावा...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 English                                            Marathi\n",
              "41023  just saying you do not like fish because of th...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "41024  the japanese parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "41025  tom tried to sell his old vcr instead of throw...  टॉमने त्याचा जुना व्हीसीआर फेकून टाकण्याऐवजी व...\n",
              "41026  you cannot view flash content on an ipad howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही पण तुम्ही त्या...\n",
              "41027  in  roger miller recorded a song called you do...  मध्ये रॉजर मिलरने यू डोन्ट वॉन्ट माय लव्ह नावा..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdY8qo2Cg09L"
      },
      "source": [
        "This data is cleaned in notebook of [EDA](https://github.com/AdiShirsath/Neural-Machine-Translation/blob/master/EDA_And_Cleaning_Text.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emZRmgzChLYd"
      },
      "source": [
        "#### First most important thing is we have to add special tokens in each target language at start SOS and EOS at end reason of this is The length of translated sentence might not be same as other language so it is to tell model where is start and end of sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15104303-ee91-4eff-bc9c-ed47916f4481"
      },
      "source": [
        "df.Marathi = df.Marathi.apply(lambda x: 'sos '+ x +' eos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7uCHZ7iaM0W"
      },
      "source": [
        "# get english and marathi in one list\n",
        "eng_texts = df.English.to_list()\n",
        "mar_texts = df.Marathi.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aNL83ChadVb"
      },
      "source": [
        "## Tokenizer\n",
        "Deep learning NN's does not accept text so first have to convert them into numbers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9fg2-rjagoQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQgPLI3ao0V"
      },
      "source": [
        "def tokenize_sent(text):\n",
        "  '''\n",
        "  Take list on texts as input and \n",
        "  returns its tokenizer and enocded text\n",
        "  '''\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text)\n",
        "\n",
        "  return tokenizer, tokenizer.texts_to_sequences(text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsLqMC61bKqV"
      },
      "source": [
        "eng_tokenizer, eng_encoded= tokenize_sent(text= eng_texts)\n",
        "mar_tokenizer, mar_encoded= tokenize_sent(text= mar_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e0kxonHbqcb",
        "outputId": "af36a282-180a-4379-a61b-3a9ccb932417"
      },
      "source": [
        "eng_encoded[100:105]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 26, 1541], [18, 3, 591], [18, 3, 21], [18, 3, 21], [21, 130]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgcQY325bsr2"
      },
      "source": [
        "eng_index_word = eng_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DTU8OCub8M_",
        "outputId": "7add0ed2-13f9-45f8-843a-7e3777bab89b"
      },
      "source": [
        "ENG_VOCAB_SIZE = len(eng_tokenizer.word_counts)+1\n",
        "ENG_VOCAB_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdPsaSYHcLJf",
        "outputId": "76472694-9bc6-4b51-b830-31510e9d25c9"
      },
      "source": [
        "mar_encoded[30000:30005]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 190, 17, 2954, 45, 2],\n",
              " [1, 10307, 10308, 5956, 381, 150, 2],\n",
              " [1, 80, 986, 13, 46, 51, 217, 2],\n",
              " [1, 121, 52, 187, 260, 596, 2],\n",
              " [1, 40, 52, 187, 260, 596, 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwdkNIUOcND7"
      },
      "source": [
        "mar_index_word= mar_tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aFy3fOYF1_n"
      },
      "source": [
        "mar_word_index =mar_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhQ2qcJ1cWLU",
        "outputId": "c2585c3a-5bcc-4968-b656-4eeef36d5232"
      },
      "source": [
        "MAR_VOCAB_SIZE=len(mar_tokenizer.word_counts)+1\n",
        "MAR_VOCAB_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faqGRJuYdHHX"
      },
      "source": [
        "max_eng_len = 0\n",
        "for i in range(len(eng_encoded)):\n",
        "  if len(eng_encoded[i]) > max_eng_len:\n",
        "    max_eng_len= len(eng_encoded[i])\n",
        "\n",
        "max_mar_len = 0\n",
        "for i in range(len(mar_encoded)):\n",
        "  if len(eng_encoded[i]) > max_mar_len:\n",
        "    max_mar_len= len(mar_encoded[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua8cyluif43t",
        "outputId": "fbd58198-34a0-4640-eadc-bc696c165d66"
      },
      "source": [
        "print(max_eng_len)\n",
        "max_mar_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFYbSMx2jpcn"
      },
      "source": [
        "## Padding \n",
        "We can not sent sentences with different length in neural net so padd them with zero "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0nJk0VcwNV"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxM5e1Xhc4oq"
      },
      "source": [
        "# Use max length for padding for eng and marathi\n",
        "eng_padded = pad_sequences(eng_encoded, maxlen=max_eng_len, padding='post')\n",
        "mar_padded = pad_sequences(mar_encoded, maxlen=max_mar_len, padding='post')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpWVO9ZUgQlK",
        "outputId": "c57d3b4c-eb66-4809-f13e-4419b3723631"
      },
      "source": [
        "eng_padded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41028, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_eCExefgTIu",
        "outputId": "234dd5b7-54d4-4da5-e66e-c6ae286262b0"
      },
      "source": [
        "mar_padded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41028, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4a5Wg33ir55"
      },
      "source": [
        "# Convert them into array\n",
        "eng_padded= np.array(eng_padded)\n",
        "mar_padded= np.array(mar_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DpbSrugkHkk"
      },
      "source": [
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDErgK3gogI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Epi5UGEgr4i"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(eng_padded, mar_padded, test_size=0.1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnElMyebhESu",
        "outputId": "523a9954-49a0-45fd-ae3e-78542c013a33"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36925, 36), (4103, 36), (36925, 37), (4103, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_ruAVmJkOaJ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "549a9719-6cfa-45e8-8b0b-6a8d54f8a4dd"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, Bidirectional, Add, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LjnGYbKaujb"
      },
      "source": [
        "# Eoncoder\n",
        "encoder_input = Input(shape=(None, ))\n",
        "encoder_embd = Embedding(ENG_VOCAB_SIZE,512, mask_zero=True)(encoder_input)\n",
        "encoder_lstm = Bidirectional(LSTM(256, return_state=True))\n",
        "encoder_output, forw_state_h, forw_state_c, back_state_h, back_state_c = encoder_lstm(encoder_embd)\n",
        "state_h_final = Concatenate()([forw_state_h, back_state_h])\n",
        "state_c_final = Concatenate()([forw_state_c, back_state_c])\n",
        "\n",
        "## Now take only states and create context vector\n",
        "encoder_states= [state_h_final, state_c_final]\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(None,))\n",
        "# For zero padding we have added +1 in marathi vocab size\n",
        "decoder_embd = Embedding(MAR_VOCAB_SIZE, 512, mask_zero=True)\n",
        "decoder_embedding= decoder_embd(decoder_input)\n",
        "# We used bidirectional layer above so we have to double units of this lstm\n",
        "decoder_lstm = LSTM(512, return_state=True,return_sequences=True )\n",
        "# just take output of this decoder dont need self states\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "# here this is going to predicct so we can add dense layer here\n",
        "# here we want to convert predicted numbers into probability so use softmax\n",
        "decoder_dense= Dense(MAR_VOCAB_SIZE, activation='softmax')\n",
        "# We will again feed predicted output into decoder to predict its next word\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model5 = Model([encoder_input, decoder_input], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "KDdVvq1SFRR8",
        "outputId": "de213951-0282-48ce-81a3-9de63ab04542"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wph16NQ7Dl5A",
        "outputId": "0117fbc5-2902-4f40-ede6-241f920b45d7"
      },
      "source": [
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 512)    2888192     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 512), (None, 1574912     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 512)    7024640     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 512),  2099200     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 13720)  7038360     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 20,625,304\n",
            "Trainable params: 20,625,304\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYJ324RQDxb8",
        "outputId": "2d0d6149-f929-491c-c4c1-e7b3630cd4b7"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   13,  445, ...,    0,    0,    0],\n",
              "       [   1,   14,   20, ...,    0,    0,    0],\n",
              "       [   1,    4,  109, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,   23,  257, ...,    0,    0,    0],\n",
              "       [   1,  170, 1575, ...,    0,    0,    0],\n",
              "       [   1,   14, 1033, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP51fayiDzHy",
        "outputId": "fb4e1e0e-00d7-48db-b76c-064f846d9918"
      },
      "source": [
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 512)    2888192     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 512), (None, 1574912     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 512)    7024640     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 512),  2099200     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 13720)  7038360     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 20,625,304\n",
            "Trainable params: 20,625,304\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqj60LBkD2Jq"
      },
      "source": [
        "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79t27AODkTUI"
      },
      "source": [
        "#### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_MJI6y5rBsM"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/\", monitor='val_accuracy')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "callbacks_list = [checkpoint, early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m239tOtErBpm"
      },
      "source": [
        "EPOCHS= 50 #@param {type:'slider',min:10,max:100, step:10 }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_rFGBg-kWmM"
      },
      "source": [
        "### Prepare input for encoder -decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2UDxr_4J7J"
      },
      "source": [
        "# Training\n",
        "encoder_input_data = X_train\n",
        "decoder_input_data = y_train[:,:-1]\n",
        "decoder_target_data = y_train[:,1:]\n",
        "\n",
        "# Testing\n",
        "encoder_input_test = X_test\n",
        "decoder_input_test = y_test[:,:-1]\n",
        "decoder_target_test= y_test[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gk8U0gD66U",
        "outputId": "e8464b27-a20f-42b7-af0f-816b6a543cbd"
      },
      "source": [
        "history = model5.fit([encoder_input_data, decoder_input_data],decoder_target_data, \n",
        "                    epochs=EPOCHS, \n",
        "                    batch_size=128,\n",
        "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test ),\n",
        "                     callbacks= callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "289/289 [==============================] - 61s 179ms/step - loss: 0.9475 - accuracy: 0.3151 - val_loss: 0.8124 - val_accuracy: 0.3692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.7049 - accuracy: 0.4203 - val_loss: 0.6469 - val_accuracy: 0.4628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.5364 - accuracy: 0.5109 - val_loss: 0.5290 - val_accuracy: 0.5329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "289/289 [==============================] - 49s 169ms/step - loss: 0.4005 - accuracy: 0.5909 - val_loss: 0.4501 - val_accuracy: 0.5879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.2956 - accuracy: 0.6664 - val_loss: 0.4004 - val_accuracy: 0.6280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/50\n",
            "289/289 [==============================] - 49s 169ms/step - loss: 0.2185 - accuracy: 0.7310 - val_loss: 0.3701 - val_accuracy: 0.6590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/50\n",
            "289/289 [==============================] - 49s 168ms/step - loss: 0.1634 - accuracy: 0.7872 - val_loss: 0.3513 - val_accuracy: 0.6776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.1251 - accuracy: 0.8292 - val_loss: 0.3417 - val_accuracy: 0.6888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0993 - accuracy: 0.8584 - val_loss: 0.3358 - val_accuracy: 0.6976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0811 - accuracy: 0.8786 - val_loss: 0.3327 - val_accuracy: 0.7063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0682 - accuracy: 0.8931 - val_loss: 0.3326 - val_accuracy: 0.7114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0587 - accuracy: 0.9030 - val_loss: 0.3335 - val_accuracy: 0.7133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0521 - accuracy: 0.9098 - val_loss: 0.3337 - val_accuracy: 0.7160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/50\n",
            "289/289 [==============================] - 49s 170ms/step - loss: 0.0469 - accuracy: 0.9160 - val_loss: 0.3366 - val_accuracy: 0.7167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/50\n",
            "289/289 [==============================] - 49s 169ms/step - loss: 0.0432 - accuracy: 0.9195 - val_loss: 0.3400 - val_accuracy: 0.7172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/50\n",
            "289/289 [==============================] - 49s 169ms/step - loss: 0.0405 - accuracy: 0.9223 - val_loss: 0.3397 - val_accuracy: 0.7177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/50\n",
            "289/289 [==============================] - 50s 174ms/step - loss: 0.0382 - accuracy: 0.9241 - val_loss: 0.3426 - val_accuracy: 0.7191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/50\n",
            "289/289 [==============================] - 50s 172ms/step - loss: 0.0366 - accuracy: 0.9258 - val_loss: 0.3448 - val_accuracy: 0.7184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/50\n",
            "289/289 [==============================] - 50s 173ms/step - loss: 0.0355 - accuracy: 0.9268 - val_loss: 0.3471 - val_accuracy: 0.7170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/50\n",
            "289/289 [==============================] - 50s 173ms/step - loss: 0.0347 - accuracy: 0.9268 - val_loss: 0.3494 - val_accuracy: 0.7170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/50\n",
            "289/289 [==============================] - 50s 173ms/step - loss: 0.0339 - accuracy: 0.9276 - val_loss: 0.3524 - val_accuracy: 0.7149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22/50\n",
            "289/289 [==============================] - 50s 172ms/step - loss: 0.0333 - accuracy: 0.9277 - val_loss: 0.3523 - val_accuracy: 0.7173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/model_checkpoints/model5/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUCunS2T7eox"
      },
      "source": [
        "model5.save_weights(\"/content/drive/MyDrive/ML/rnn/Machine_Translation/Encoder_decoder/saved_models/model5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev6k1unJEB_k"
      },
      "source": [
        "# inference Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prX-qe6bEcll"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding\n",
        "from tensorflow.keras import Input, Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4s98lZ4jyt"
      },
      "source": [
        "encoder_model = Model(encoder_input, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBAl6i2_4jyt"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(512,))\n",
        "decoder_state_input_c= Input(shape=(512,))\n",
        "decoder_states_input= [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_embd2 = decoder_embd(decoder_input)\n",
        "\n",
        "decoder_output2,state_h2, state_c2 = decoder_lstm(dec_embd2, initial_state=decoder_states_input)\n",
        "deccoder_states2= [state_h2, state_c2]\n",
        "\n",
        "decoder_output2 = decoder_dense(decoder_output2)\n",
        "\n",
        "decoder_model = Model(\n",
        "                      [decoder_input]+decoder_states_input,\n",
        "                      [decoder_output2]+ deccoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ujz_htekjoK"
      },
      "source": [
        "#### Converting predicted numbers into text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq7hdBLWcQY8"
      },
      "source": [
        "def get_predicted_sentence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = mar_word_index['sos']\n",
        "    \n",
        "    # Sampling loop for a batch of sequences\n",
        "\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index==0:\n",
        "          break\n",
        "        else:   \n",
        "         # convert max index number to marathi word\n",
        "         sampled_char = mar_index_word[sampled_token_index]\n",
        "        # aapend it ti decoded sent\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        \n",
        "        # Exit condition: either hit max length or find stop token.\n",
        "        if (sampled_char == 'eos' or len(decoded_sentence) >= 37):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqDslyeqn1_f"
      },
      "source": [
        "def get_marathi_sentence(sequence):\n",
        "  sentence=\"\"\n",
        "  for i in sequence:\n",
        "    if ((i != 0 and i != mar_word_index['sos']) and i != mar_word_index['eos']):\n",
        "      sentence = sentence + mar_index_word[i]+' '\n",
        "  return sentence\n",
        "\n",
        "def get_eng_sent(sequence):\n",
        "    sentence =''\n",
        "    for i in sequence:\n",
        "      if(i!=0):\n",
        "        sentence = sentence + eng_index_word[i]+' '\n",
        "    return sentence       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoYzpFcIi5sm",
        "outputId": "86612e7f-4170-4214-8f34-5626159feb14"
      },
      "source": [
        "for i in range(20):\n",
        "  print(\"English sentence:\",get_eng_sent(X_test[i]))\n",
        "  print(\"Actual Marathi Sentence:\",get_marathi_sentence(y_test[i]))\n",
        "  print(\"Translated Marathi Sentence:\",get_predicted_sentence(X_test[i].reshape(1,36))[:-4])\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English sentence: i was calling my friend \n",
            "Actual Marathi Sentence: मी माझ्या मित्राला बोलवत होतो \n",
            "Translated Marathi Sentence:  मी माझ्या मैत्रिणीला फोन करत होते\n",
            "\n",
            "\n",
            "English sentence: i like coffee \n",
            "Actual Marathi Sentence: मला कॉफी आवडते \n",
            "Translated Marathi Sentence:  मला कॉफी आवडते\n",
            "\n",
            "\n",
            "English sentence: you cannot view flash content on an ipad however you can easily email yourself the urls of these web pages and view that content on your regular computer when you get home \n",
            "Actual Marathi Sentence: आयपॅडवर फ्लॅश आशय बघता येत नाही पण तुम्ही त्या वेब पानांचे यूआरएल स्वतःला ईमेल करून तोच आशय घरी पोहोचल्यावर आपल्या रोजच्या संगणकावर पाहू शकता \n",
            "Translated Marathi Sentence:  जर तू भारतापासून शहर रेकॉर्ड करू\n",
            "\n",
            "\n",
            "English sentence: he likes english very much \n",
            "Actual Marathi Sentence: त्यांना इंग्रजी खूप आवडते \n",
            "Translated Marathi Sentence:  त्याला इंग्रजी खूप आवडते\n",
            "\n",
            "\n",
            "English sentence: i do not like shopping with you \n",
            "Actual Marathi Sentence: मला तुझ्याबरोबर शॉपिंग करायला आवडत नाही \n",
            "Translated Marathi Sentence:  मला तुमच्यासोबत खरेदी करायला आवडत \n",
            "\n",
            "\n",
            "English sentence: what are you doing here now \n",
            "Actual Marathi Sentence: तू आता इथे काय करत आहेस \n",
            "Translated Marathi Sentence:  तू आता इथे काय करत आहेस\n",
            "\n",
            "\n",
            "English sentence: this room has three windows \n",
            "Actual Marathi Sentence: या खोलीत तीन खिडक्या आहेत \n",
            "Translated Marathi Sentence:  ही खोली रिकामी आहेत\n",
            "\n",
            "\n",
            "English sentence: will you tell me \n",
            "Actual Marathi Sentence: तुम्ही मला सांगाल का \n",
            "Translated Marathi Sentence:  मला सांगाल का\n",
            "\n",
            "\n",
            "English sentence: they arrested tom last night \n",
            "Actual Marathi Sentence: त्यांनी काल रात्री टॉमला अटक केली \n",
            "Translated Marathi Sentence:  त्यांनी काल रात्री टॉमला अटक केली\n",
            "\n",
            "\n",
            "English sentence: i studied for one hour \n",
            "Actual Marathi Sentence: मी एक तास अभ्यास केला \n",
            "Translated Marathi Sentence:  मी एक तास टीव्ही केलं\n",
            "\n",
            "\n",
            "English sentence: i like cats \n",
            "Actual Marathi Sentence: मला मांजरी आवडतात \n",
            "Translated Marathi Sentence:  मला मांजरी आवडतात\n",
            "\n",
            "\n",
            "English sentence: she reserved a room \n",
            "Actual Marathi Sentence: त्यांनी एक खोली आरक्षित केली \n",
            "Translated Marathi Sentence:  तिने एक खोली आरक्षित केली\n",
            "\n",
            "\n",
            "English sentence: he added sugar to his coffee \n",
            "Actual Marathi Sentence: त्याने आपल्या कॉफीत साखर घातली \n",
            "Translated Marathi Sentence:  त्याने आपल्या कॉफीत साखर घातली\n",
            "\n",
            "\n",
            "English sentence: i want more \n",
            "Actual Marathi Sentence: मला अजून हवं आहे \n",
            "Translated Marathi Sentence:  मला अजून हवंय\n",
            "\n",
            "\n",
            "English sentence: the shop was crowded with young people \n",
            "Actual Marathi Sentence: दुकानात तरुणांची गर्दी होती \n",
            "Translated Marathi Sentence:  दुकानात तरुणांनी गर्दी केलेली\n",
            "\n",
            "\n",
            "English sentence: what we are doing now is very dangerous \n",
            "Actual Marathi Sentence: आपण आता जे करत आहोत ते अतिशय धोकादायक आहे \n",
            "Translated Marathi Sentence:  आम्ही आता जे करत आहोत ते अतिशय धोका\n",
            "\n",
            "\n",
            "English sentence: did you buy that book \n",
            "Actual Marathi Sentence: तू ते पुस्तक विकत घेतलंस का \n",
            "Translated Marathi Sentence:  ते पुस्तक विकत घेतलंस का\n",
            "\n",
            "\n",
            "English sentence: tom wiped marys tears away \n",
            "Actual Marathi Sentence: टॉमने मेरीचे आश्रू पुसून टाकले \n",
            "Translated Marathi Sentence:  टॉमने आपला चष्मा पुसला\n",
            "\n",
            "\n",
            "English sentence: i am downloading books \n",
            "Actual Marathi Sentence: मी पुस्तकं डाउनलोड करतोय \n",
            "Translated Marathi Sentence:  मी पुस्तकं डाउनलोड करतेय\n",
            "\n",
            "\n",
            "English sentence: i lost everything i had \n",
            "Actual Marathi Sentence: माझ्याकडे जे काही होतं ते सर्व मी गमवून बसलो \n",
            "Translated Marathi Sentence:  माझ्याकडे जे काही होतं ते सर्व मी ग\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iN3hbBbpE28"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}